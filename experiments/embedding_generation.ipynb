{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm"
   ],
   "id": "42c2be4a77416b83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "BATCH_SIZE = 8\n",
    "DATAFRAME_PATH = \"../data/custom_fragments2/datasets/random_equal_distribution/random_equal_val.csv\"\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ],
   "id": "6c35ca311a486078"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#df = pd.read_csv(DATAFRAME_PATH)\n",
    "df = fragment_df\n",
    "df.head()"
   ],
   "id": "8e0ab056eb4b432"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(df)",
   "id": "a2b1d3702f3efd19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", do_lower_case=False)\n",
    "model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\")\n",
    "model.to(DEVICE)\n",
    "model.eval()"
   ],
   "id": "821d5bde63831958"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Filter sequences by length and create a proper copy to avoid SettingWithCopyWarning\n",
    "length_df = df[df[\"fragment_length\"] <= 1024].copy()\n",
    "length_df.head()"
   ],
   "id": "8b119466cff9c910"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "length_df[\"sequence_split\"] = length_df[\"sequence\"].apply(\n",
    "    lambda seq: \" \".join(list(re.sub(r\"[UZOB]\", \"X\", seq)))\n",
    ")\n",
    "length_df.head()"
   ],
   "id": "4288a75db17fa490"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tokenized_df = pd.DataFrame(data=length_df[[\"source_accession\", \"is_fragment\", \"sequence_split\"]])\n",
    "tokenized_df.head()"
   ],
   "id": "1aa3c72d16a11630"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tokenized_input = []",
   "id": "29b7d50e2ba3c807"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for i in tqdm(range(0, len(tokenized_df), BATCH_SIZE)):\n",
    "    batch = tokenized_df.loc[i:i+BATCH_SIZE - 1]\n",
    "\n",
    "    encoded = tokenizer.batch_encode_plus(\n",
    "        batch[\"sequence_split\"],\n",
    "        add_special_tokens=True,\n",
    "        padding=\"longest\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for acc_id, is_fragment, input_ids, attention_mask in zip(batch[\"source_accession\"], batch[\"is_fragment\"], encoded[\"input_ids\"], encoded[\"attention_mask\"]):\n",
    "        output.append((acc_id, is_fragment, input_ids, attention_mask))\n",
    "\n",
    "    tokenized_input.append(output)"
   ],
   "id": "8f5a62b3571b1bf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tokenized_input[0]",
   "id": "3dfb67a10b972fbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize as a list (not dict) since we'll use append\n",
    "all_embeddings = []"
   ],
   "id": "fffe1077239d1ad7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create embeddings directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(\"./true_fragment_embeddings\", exist_ok=True)\n",
    "print(\"Embeddings directory ready\")"
   ],
   "id": "fc263f980f261ca4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test cell - checking embedding generation for a single sequence\n",
    "with torch.no_grad():\n",
    "    for (batch_num, entries) in tqdm(enumerate(tokenized_input), total=len(tokenized_input)):\n",
    "        for acc_id, is_fragment, input_ids, attention_mask in entries:\n",
    "            # Add batch dimension [seq_len] -> [1, seq_len]\n",
    "            embedding = model(\n",
    "                input_ids=input_ids.unsqueeze(0).to(DEVICE),\n",
    "                attention_mask=attention_mask.unsqueeze(0).to(DEVICE)\n",
    "            ).last_hidden_state\n",
    "            print(f\"Accession ID: {acc_id}\")\n",
    "            print(f\"Fragment: {is_fragment}\")\n",
    "            print(f\"Embedding shape: {embedding.shape}\")  # Should be [1, seq_len, 1024]\n",
    "            print(f\"Attention mask shape: {attention_mask.shape}\")  # Should be [seq_len]\n",
    "            break\n",
    "        break"
   ],
   "id": "4fd8089a656d255d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Main embedding generation with mean pooling\n",
    "with torch.no_grad():\n",
    "    for (batch_num, entries) in tqdm(enumerate(tokenized_input), total=len(tokenized_input)):\n",
    "        # Collect batch data\n",
    "        acc_ids = []\n",
    "        fragment_status = []\n",
    "        batch_input_ids = []\n",
    "        batch_attention_masks = []\n",
    "        \n",
    "        for (acc_id, is_fragment, input_ids, attention_mask) in entries:\n",
    "            acc_ids.append(acc_id)\n",
    "            fragment_status.append(is_fragment)\n",
    "            batch_input_ids.append(input_ids)\n",
    "            batch_attention_masks.append(attention_mask)\n",
    "        \n",
    "        # Stack into proper batches [batch_size, seq_len]\n",
    "        batch_input_ids = torch.stack(batch_input_ids).to(DEVICE)\n",
    "        batch_attention_masks = torch.stack(batch_attention_masks).to(DEVICE)\n",
    "        \n",
    "        # Get embeddings [batch_size, seq_len, embedding_dim]\n",
    "        embeddings = model(\n",
    "            input_ids=batch_input_ids,\n",
    "            attention_mask=batch_attention_masks\n",
    "        ).last_hidden_state\n",
    "        \n",
    "        # Mean pooling: average over sequence length, weighted by attention mask\n",
    "        # Expand attention mask to match embedding dimensions\n",
    "        mask = batch_attention_masks.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "        \n",
    "        # Sum embeddings where attention mask is 1\n",
    "        summed = torch.sum(embeddings * mask, dim=1)\n",
    "        # Count how many positions were summed (sequence lengths)\n",
    "        lengths = torch.sum(mask, dim=1)\n",
    "        # Average: [batch_size, embedding_dim]\n",
    "        prot_embeds = summed / lengths\n",
    "        \n",
    "        # Store embeddings with their accession IDs\n",
    "        for i, (acc_id, is_fragment) in enumerate(zip(acc_ids, fragment_status)):\n",
    "            all_embeddings.append((acc_id, is_fragment, prot_embeds[i].cpu()))\n",
    "        \n",
    "        # Progress logging\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f\"Processed {batch_num * BATCH_SIZE} sequences...\")\n",
    "        \n",
    "        # Periodic saving\n",
    "        if batch_num % 1000 == 0 and batch_num > 0:\n",
    "            with open(f\"./true_fragment_embeddings/embeddings_{batch_num}.pkl\", \"wb\") as p:\n",
    "                pickle.dump(all_embeddings, p)\n",
    "            print(f\"Saved checkpoint at batch {batch_num}\")\n",
    "\n",
    "# Save final embeddings\n",
    "with open(f\"./true_fragment_embeddings/final_embeddings.pkl\", \"wb\") as p:\n",
    "    pickle.dump(all_embeddings, p)\n",
    "    \n",
    "print(f\"\\nComplete! Generated {len(all_embeddings)} embeddings.\")"
   ],
   "id": "9f6a3f57d90adbd8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Verification: Load and inspect embeddings\n",
    "with open(\"./embeddings/final_embeddings.pkl\", \"rb\") as p:\n",
    "    loaded_embeddings = pickle.load(p)\n",
    "\n",
    "print(f\"Total embeddings: {len(loaded_embeddings)}\")\n",
    "print(f\"\\nFirst embedding:\")\n",
    "print(f\"  Accession ID: {loaded_embeddings[2][0]}\")\n",
    "print(f\"  Embedding shape: {loaded_embeddings[2][2].shape}\")\n",
    "print(f\"  Embedding type: {type(loaded_embeddings[2][2])}\")\n",
    "print(f\"  Is Fragment: {loaded_embeddings[2][1]}\")\n",
    "print(f\"\\nExpected: torch.Size([1024]) for ProtT5-XL\")"
   ],
   "id": "398937a5cc8bd7e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[df[\"source_accession\"] == \"A3Q8S8\"]",
   "id": "3b0ac48ce0a7d5c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "bool(tokenized_df.loc[0][\"is_fragment\"]) == True",
   "id": "e1d7724fa8f21502"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tokenized_df.loc[60607][\"is_fragment\"]",
   "id": "b4d8a145e6e3c2e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create embedding df\n",
    "csv_test = \"\\n\".join(f\"{acc_id},{\",\".join(str(v.item()) for v in embedding)}\" for acc_id, embedding in loaded_embeddings)\n",
    "\n",
    "with open(\"test.csv\", \"w\") as f:\n",
    "    f.write(csv_test)"
   ],
   "id": "7ebc062e7f724be9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(csv_test)",
   "id": "574ce7fd529d0538"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "header = \"acc_id,\" + \",\".join(str(i) for i in range(1024))\n",
    "header"
   ],
   "id": "f0106f5dc154ea8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(tokenized_df)",
   "id": "1ce09d912aacd9da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# add fragment label to list and store are pickle\n",
    "annotated_embeddings = []\n",
    "\n",
    "for i, (acc_id, embedding) in enumerate(loaded_embeddings):\n",
    "    annotation = bool(tokenized_df.loc[i][\"is_fragment\"])\n",
    "    annotated_embeddings.append((acc_id, embedding, annotation))"
   ],
   "id": "6057dd4c373fb378"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## generation of real fragments",
   "id": "2a6051a0807473b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fragment_df = pd.read_csv(\"./uniprotkb_reviewed_true_AND_fragment_tr_2025_12_01.tsv\", sep=\"\\t\")\n",
    "fragment_df"
   ],
   "id": "d98f48d59c91145a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fragment_df[\"fragment_length\"] = [len(seq) for seq in fragment_df[\"sequence\"]]\n",
    "fragment_df"
   ],
   "id": "c62c24d524097901"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fragment_df = fragment_df.rename(columns={\"entry\": \"source_accession\"})\n",
    "fragment_df"
   ],
   "id": "862a53f0a90fb5b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fragment_df[\"is_fragment\"] = True\n",
    "fragment_df"
   ],
   "id": "283e1571f3a9eb09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "95ad9cdb92b12feb"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
