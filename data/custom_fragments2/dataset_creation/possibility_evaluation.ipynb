{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-18T22:27:42.508572Z",
     "start_time": "2025-11-18T22:27:42.506180Z"
    }
   },
   "source": [
    "import ijson\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:05:41.939163Z",
     "start_time": "2025-11-18T22:05:41.937530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TARGET_FRAGMENT_TYPES = [\n",
    "    'terminal_N',\n",
    "    'terminal_C',\n",
    "    'terminal_both',\n",
    "    'internal_gap',\n",
    "    'mixed'\n",
    "]"
   ],
   "id": "527e2ae9942965de",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:24:39.627712Z",
     "start_time": "2025-11-18T22:24:39.552094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load current valid ids\n",
    "TRAIN_SET = set()\n",
    "with open(\"../data/train.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        TRAIN_SET.add(line[:-1])\n",
    "\n",
    "VAL_SET = set()\n",
    "with open(\"../data/val.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        VAL_SET.add(line[:-1])\n",
    "\n",
    "TEST_SET = set()\n",
    "with open(\"../data/test.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        TEST_SET.add(line[:-1])\n",
    "\n",
    "COMPLETE = TRAIN_SET.union(VAL_SET).union(TEST_SET)\n",
    "\n",
    "print(len(TRAIN_SET))\n",
    "print(len(VAL_SET))\n",
    "print(len(TEST_SET))\n",
    "print(len(COMPLETE))\n",
    "print(len(COMPLETE) == len(TRAIN_SET) + len(VAL_SET) + len(TEST_SET))"
   ],
   "id": "5f7ee270dcde26e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243444\n",
      "60861\n",
      "76077\n",
      "380382\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:26:17.733614Z",
     "start_time": "2025-11-18T22:26:17.730226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_domains(features):\n",
    "    domains = []\n",
    "    for feature in features:\n",
    "        if feature.get('type') == 'Domain':\n",
    "            location = feature.get('location', {})\n",
    "            start_info = location.get('start', {})\n",
    "            end_info = location.get('end', {})\n",
    "\n",
    "            # Get start and end positions\n",
    "            start = start_info.get('value')\n",
    "            end = end_info.get('value')\n",
    "\n",
    "            if start is not None and end is not None:\n",
    "                domains.append({\n",
    "                    \"start\": int(start),\n",
    "                    \"end\": int(end),\n",
    "                    \"description\": feature.get(\"description\", \"\")\n",
    "                })\n",
    "\n",
    "    return sorted(domains, key=lambda x: x[\"start\"])\n",
    "\n",
    "\n",
    "def categorize_protein(domains, seq_length):\n",
    "    if not domains:\n",
    "        return []\n",
    "\n",
    "    fragment_types = []\n",
    "\n",
    "    has_n_term = False\n",
    "    has_c_term = False\n",
    "    has_intern = False\n",
    "\n",
    "    for domain in domains:\n",
    "        if domain[\"start\"] == 1:\n",
    "            has_n_term = True\n",
    "        elif domain[\"end\"] == seq_length:\n",
    "            has_c_term = True\n",
    "        else:\n",
    "            if domain[\"start\"] > 1 and domain[\"end\"] < seq_length:\n",
    "                has_intern = True\n",
    "\n",
    "    if has_n_term:\n",
    "        fragment_types.append(\"terminal_N\")\n",
    "\n",
    "    if has_c_term:\n",
    "        fragment_types.append(\"terminal_C\")\n",
    "\n",
    "    if has_n_term and has_c_term:\n",
    "        fragment_types.append(\"terminal_both\")\n",
    "\n",
    "    if has_intern:\n",
    "        fragment_types.append(\"internal_gap\")\n",
    "\n",
    "    if (has_n_term or has_c_term) and has_intern:\n",
    "        fragment_types.append(\"mixed\")\n",
    "\n",
    "    return fragment_types\n",
    "\n",
    "\n",
    "def is_valid_protein(record):\n",
    "    protein_desc = record.get('proteinDescription', {})\n",
    "    if protein_desc.get('flag') == 'Fragment':\n",
    "        return False\n",
    "\n",
    "    sequence = record.get('sequence', {}).get('value')\n",
    "    if not sequence:\n",
    "        return False\n",
    "\n",
    "    if len(sequence) < 10:\n",
    "        return False\n",
    "\n",
    "    return True"
   ],
   "id": "6630be13b30b9471",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:28:58.253186Z",
     "start_time": "2025-11-18T22:27:45.842642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_protein_pools = defaultdict(list)\n",
    "train_protein_data = []\n",
    "\n",
    "val_protein_pools = defaultdict(list)\n",
    "val_protein_data = []\n",
    "\n",
    "test_protein_pools = defaultdict(list)\n",
    "test_protein_data = []\n",
    "\n",
    "stats = {\n",
    "    'total_processed': 0,\n",
    "    'valid_proteins': 0,\n",
    "    'fragments_skipped': 0,\n",
    "    'no_sequence': 0,\n",
    "    'too_short': 0,\n",
    "    'with_domains': 0,\n",
    "    'without_domains': 0\n",
    "}\n",
    "\n",
    "print(\"Loading SwissProt database...\")\n",
    "\n",
    "with open(\"../data/uniprotkb_reviewed_true_2025_11_07.json\", 'r') as f:\n",
    "    # Use tqdm for progress bar\n",
    "    for record in tqdm(ijson.items(f, 'results.item'), desc=\"Processing proteins\"):\n",
    "        stats['total_processed'] += 1\n",
    "\n",
    "        if not record[\"primaryAccession\"] in COMPLETE:\n",
    "            continue\n",
    "\n",
    "        # Check if protein is valid\n",
    "        if not is_valid_protein(record):\n",
    "            protein_desc = record.get('proteinDescription', {})\n",
    "            if protein_desc.get('flag') == 'Fragment':\n",
    "                stats['fragments_skipped'] += 1\n",
    "            elif not record.get('sequence', {}).get('value'):\n",
    "                stats['no_sequence'] += 1\n",
    "            elif len(record.get(\"sequence\", {}).get(\"value\")) < 10:\n",
    "                stats['too_short'] += 1\n",
    "            continue\n",
    "\n",
    "        stats['valid_proteins'] += 1\n",
    "\n",
    "        # Extract protein info\n",
    "        acc_id = record['primaryAccession']\n",
    "        sequence = record['sequence']['value']\n",
    "        seq_length = len(sequence)\n",
    "        features = record.get('features', [])\n",
    "\n",
    "        # Extract domain annotations\n",
    "        domains = extract_domains(features)\n",
    "\n",
    "        if domains:\n",
    "            stats['with_domains'] += 1\n",
    "        else:\n",
    "            stats['without_domains'] += 1\n",
    "\n",
    "        # Store protein data\n",
    "        protein_info = {\n",
    "            'acc_id': acc_id,\n",
    "            'sequence': sequence,\n",
    "            'length': seq_length,\n",
    "            'domains': domains,\n",
    "            'n_domains': len(domains)\n",
    "        }\n",
    "\n",
    "        # Categorize protein by fragment generation capability\n",
    "        fragment_types = categorize_protein(domains, seq_length)\n",
    "        protein_info['can_generate'] = fragment_types\n",
    "\n",
    "        if acc_id in TRAIN_SET:\n",
    "            train_protein_data.append(protein_info)\n",
    "\n",
    "            # Add to appropriate pools\n",
    "            for ftype in fragment_types:\n",
    "                train_protein_pools[ftype].append(protein_info)\n",
    "\n",
    "        elif acc_id in TEST_SET:\n",
    "            test_protein_data.append(protein_info)\n",
    "\n",
    "            # Add to appropriate pools\n",
    "            for ftype in fragment_types:\n",
    "                test_protein_pools[ftype].append(protein_info)\n",
    "\n",
    "        elif acc_id in VAL_SET:\n",
    "            val_protein_data.append(protein_info)\n",
    "\n",
    "            # Add to appropriate pools\n",
    "            for ftype in fragment_types:\n",
    "                val_protein_pools[ftype].append(protein_info)\n",
    "\n",
    "print(\"\\n✓ Loading complete!\")"
   ],
   "id": "b546f288b122bbe4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SwissProt database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing proteins: 573661it [01:12, 7922.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loading complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:29:19.756765Z",
     "start_time": "2025-11-18T22:29:19.754098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# stats\n",
    "print(\"SwissProt Database Statistics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total records processed:      {stats['total_processed']:>10,}\")\n",
    "print(f\"Valid complete proteins:      {stats['valid_proteins']:>10,}\")\n",
    "print(f\"  - With domain annotations:  {stats['with_domains']:>10,}\")\n",
    "print(f\"  - Without domain annotations:{stats['without_domains']:>10,}\")\n",
    "print(f\"\\nSkipped records:\")\n",
    "print(f\"  - Already fragments:        {stats['fragments_skipped']:>10,}\")\n",
    "print(f\"  - No sequence:              {stats['no_sequence']:>10,}\")\n",
    "print(f\"  - Too short (<10 aa):       {stats['too_short']:>10,}\")\n",
    "print(\"=\"*60)"
   ],
   "id": "1a5f699c353eb3e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwissProt Database Statistics:\n",
      "============================================================\n",
      "Total records processed:         573,661\n",
      "Valid complete proteins:         373,953\n",
      "  - With domain annotations:      92,823\n",
      "  - Without domain annotations:   281,130\n",
      "\n",
      "Skipped records:\n",
      "  - Already fragments:             5,980\n",
      "  - No sequence:                       0\n",
      "  - Too short (<50 aa):              449\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:32:01.175763Z",
     "start_time": "2025-11-18T22:32:01.172885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nProtein Pool Sizes by Fragment Type (TRAIN):\")\n",
    "print(\"=\"*60)\n",
    "for ftype in TARGET_FRAGMENT_TYPES:\n",
    "    count = len(train_protein_pools[ftype])\n",
    "    pct = (count / len(TRAIN_SET) * 100) if stats['valid_proteins'] > 0 else 0\n",
    "    print(f\"{ftype:20s}: {count:>8,} proteins ({pct:>5.2f}%)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Total protein entries':20s}: {len(train_protein_data):>8,}\")\n",
    "print(\"\\nNote: A single protein can belong to multiple pools\")"
   ],
   "id": "3ae7f7d31e36a0d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Protein Pool Sizes by Fragment Type (TRAIN):\n",
      "============================================================\n",
      "terminal_N          :    4,188 proteins ( 1.72%)\n",
      "terminal_C          :    7,526 proteins ( 3.09%)\n",
      "terminal_both       :      276 proteins ( 0.11%)\n",
      "internal_gap        :   51,520 proteins (21.16%)\n",
      "mixed               :    3,619 proteins ( 1.49%)\n",
      "============================================================\n",
      "Total protein entries:  239,300\n",
      "\n",
      "Note: A single protein can belong to multiple pools\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:32:03.363136Z",
     "start_time": "2025-11-18T22:32:03.360342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nProtein Pool Sizes by Fragment Type (VAL):\")\n",
    "print(\"=\"*60)\n",
    "for ftype in TARGET_FRAGMENT_TYPES:\n",
    "    count = len(val_protein_pools[ftype])\n",
    "    pct = (count / len(VAL_SET) * 100) if stats['valid_proteins'] > 0 else 0\n",
    "    print(f\"{ftype:20s}: {count:>8,} proteins ({pct:>5.2f}%)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Total protein entries':20s}: {len(val_protein_data):>8,}\")\n",
    "print(\"\\nNote: A single protein can belong to multiple pools\")"
   ],
   "id": "4b0cdc705f1690d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Protein Pool Sizes by Fragment Type (VAL):\n",
      "============================================================\n",
      "terminal_N          :    1,108 proteins ( 1.82%)\n",
      "terminal_C          :    1,822 proteins ( 2.99%)\n",
      "terminal_both       :       71 proteins ( 0.12%)\n",
      "internal_gap        :   12,958 proteins (21.29%)\n",
      "mixed               :      938 proteins ( 1.54%)\n",
      "============================================================\n",
      "Total protein entries:   59,857\n",
      "\n",
      "Note: A single protein can belong to multiple pools\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:32:04.725404Z",
     "start_time": "2025-11-18T22:32:04.722675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nProtein Pool Sizes by Fragment Type (TEST):\")\n",
    "print(\"=\"*60)\n",
    "for ftype in TARGET_FRAGMENT_TYPES:\n",
    "    count = len(test_protein_pools[ftype])\n",
    "    pct = (count / len(TEST_SET) * 100) if stats['valid_proteins'] > 0 else 0\n",
    "    print(f\"{ftype:20s}: {count:>8,} proteins ({pct:>5.2f}%)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Total protein entries':20s}: {len(test_protein_data):>8,}\")\n",
    "print(\"\\nNote: A single protein can belong to multiple pools\")"
   ],
   "id": "1e927f2bcff07fe6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Protein Pool Sizes by Fragment Type (TEST):\n",
      "============================================================\n",
      "terminal_N          :    1,300 proteins ( 1.71%)\n",
      "terminal_C          :    2,267 proteins ( 2.98%)\n",
      "terminal_both       :       85 proteins ( 0.11%)\n",
      "internal_gap        :   16,255 proteins (21.37%)\n",
      "mixed               :    1,132 proteins ( 1.49%)\n",
      "============================================================\n",
      "Total protein entries:   74,796\n",
      "\n",
      "Note: A single protein can belong to multiple pools\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:37:37.264889Z",
     "start_time": "2025-11-18T22:37:37.263183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json"
   ],
   "id": "d0e1e10a110128f9",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T22:41:51.874574Z",
     "start_time": "2025-11-18T22:41:49.703552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save data\n",
    "\n",
    "df_train_proteins = pd.DataFrame([{\n",
    "    \"acc_id\": p[\"acc_id\"],\n",
    "    \"length\": p[\"length\"],\n",
    "    \"n_domains\": p[\"n_domains\"],\n",
    "    \"can_generate\": \",\".join(p[\"can_generate\"] if p[\"can_generate\"] else \"\"),\n",
    "    \"sequence\": p[\"sequence\"],\n",
    "    \"domains\": json.dumps(p[\"domains\"])\n",
    "} for p in train_protein_data])\n",
    "\n",
    "df_val_proteins = pd.DataFrame([{\n",
    "    \"acc_id\": p[\"acc_id\"],\n",
    "    \"length\": p[\"length\"],\n",
    "    \"n_domains\": p[\"n_domains\"],\n",
    "    \"can_generate\": \",\".join(p[\"can_generate\"] if p[\"can_generate\"] else \"\"),\n",
    "    \"sequence\": p[\"sequence\"],\n",
    "    \"domains\": json.dumps(p[\"domains\"])\n",
    "} for p in val_protein_data])\n",
    "\n",
    "df_test_proteins = pd.DataFrame([{\n",
    "    \"acc_id\": p[\"acc_id\"],\n",
    "    \"length\": p[\"length\"],\n",
    "    \"n_domains\": p[\"n_domains\"],\n",
    "    \"can_generate\": \",\".join(p[\"can_generate\"] if p[\"can_generate\"] else \"\"),\n",
    "    \"sequence\": p[\"sequence\"],\n",
    "    \"domains\": json.dumps(p[\"domains\"])\n",
    "} for p in test_protein_data])\n",
    "\n",
    "df_train_proteins.to_csv(\"../data/swissprot_proteins_processed_train.csv\", index=False)\n",
    "df_val_proteins.to_csv(\"../data/swissprot_proteins_processed_val.csv\", index=False)\n",
    "df_test_proteins.to_csv(\"../data/swissprot_proteins_processed_test.csv\", index=False)\n",
    "\n",
    "train_pool_assignments = {}\n",
    "val_pool_assignments = {}\n",
    "test_pool_assignments = {}\n",
    "for ftype in TARGET_FRAGMENT_TYPES:\n",
    "    train_pool_assignments[ftype] = [p[\"acc_id\"] for p in train_protein_pools[ftype]]\n",
    "    val_pool_assignments[ftype] = [p[\"acc_id\"] for p in val_protein_pools[ftype]]\n",
    "    test_pool_assignments[ftype] = [p[\"acc_id\"] for p in test_protein_pools[ftype]]\n",
    "\n",
    "with open('../data/protein_pool_assignments_train.json', 'w') as f:\n",
    "    json.dump(train_pool_assignments, f, indent=2)\n",
    "\n",
    "with open('../data/protein_pool_assignments_val.json', 'w') as f:\n",
    "    json.dump(val_pool_assignments, f, indent=2)\n",
    "\n",
    "with open('../data/protein_pool_assignments_test.json', 'w') as f:\n",
    "    json.dump(test_pool_assignments, f, indent=2)"
   ],
   "id": "cfa22784d98c6d2b",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "893fbec17f30959b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
