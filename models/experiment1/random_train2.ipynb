{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "b69e0d5beee28f93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "BATCH_SIZE = 16\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 100\n",
    "EVALUATION_DELAY = 10\n",
    "print(DEVICE)"
   ],
   "id": "f73d95a59603007"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open(\"../../data/custom_fragments_30/embeddings/final_embeddings_train.pkl\", \"rb\") as f:\n",
    "    train_embeddings = pickle.load(f)"
   ],
   "id": "e056b9d6accc68a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open(\"../../data/custom_fragments_30/embeddings/final_embeddings_val.pkl\", \"rb\") as f:\n",
    "    val_embeddings = pickle.load(f)"
   ],
   "id": "b67050b92018c5b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_embeddings[0]",
   "id": "6bf7bd2df9bbf3f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(train_embeddings)",
   "id": "5ac9cec4dea9fdf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "len(val_embeddings)",
   "id": "148607e356e9b371"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class RandomDataset(Dataset):\n",
    "    def __init__(self, embeddings):\n",
    "        self.labels = []\n",
    "        self.embeddings = []\n",
    "\n",
    "        for elem in embeddings:\n",
    "            self.labels.append(torch.tensor([elem[1]], dtype=torch.float32))\n",
    "            self.embeddings.append(elem[3])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]"
   ],
   "id": "d9b333394d975d46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "train_dataset = RandomDataset(train_embeddings)"
   ],
   "id": "15d6eef7ab615cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "val_dataset = RandomDataset(val_embeddings)"
   ],
   "id": "94f059b25c728793"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_dataset[0]",
   "id": "f2deb93e42896ab2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)"
   ],
   "id": "b38ebbf12f75f2f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class RandomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "id": "47085a71808f8347"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model1 = RandomModel()\n",
    "model1.to(DEVICE)"
   ],
   "id": "319e91ffd6cefe87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=LEARNING_RATE)"
   ],
   "id": "e2e25bdcb11f11e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_binary(dataloader, model, optimizer, loss_fn, device: str):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).float()\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = torch.sigmoid(logits)\n",
    "            predicted_labels = (preds >= 0.5).float()\n",
    "            total_correct += (predicted_labels == y).sum().item()\n",
    "\n",
    "        batch_size = y.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, accuracy"
   ],
   "id": "8e8230244fa7b4bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate_binary(dataloader, model, loss_fn, device: str):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).float()\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "\n",
    "            preds = torch.sigmoid(logits)\n",
    "            predicted_labels = (preds >= 0.5).float()\n",
    "\n",
    "            total_correct += (predicted_labels == y).sum().item()\n",
    "\n",
    "            batch_size = y.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, accuracy"
   ],
   "id": "af084552bdf54abb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "prev_loss = 10000",
   "id": "99245e4b23c1e2d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "eval_losses = []\n",
    "eval_accuracies = []\n",
    "start = 0"
   ],
   "id": "6aaa2154ba55b216"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "start_time = time.time()\n",
    "for i in range(start, EPOCHS + start):\n",
    "    print(f\"Epoch: {i}\")\n",
    "\n",
    "    train_loss, train_accuracy = train_binary(train_loader, model1, optimizer, loss_fn, DEVICE)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    print(f\"Training: Avg_Loss: {train_loss:.8f}; Accuracy: {train_accuracy:.8f}\")\n",
    "\n",
    "    if i % EVALUATION_DELAY == 0:\n",
    "        eval_loss, eval_accuracy = evaluate_binary(val_loader, model1, loss_fn, DEVICE)\n",
    "        eval_losses.append(eval_loss)\n",
    "        eval_accuracies.append(eval_accuracy)\n",
    "\n",
    "        print(f\"Validation: Avg_Loss: {eval_loss:.8f}; Accuracy: {eval_accuracy:.8f}\")\n",
    "\n",
    "        if eval_loss < prev_loss:\n",
    "            torch.save(model1.state_dict(), f\"./model_saves2/random_model_epoch_{i}.pt\")\n",
    "            print(f\"\\033[92mSaved Model at epoch {i}\\033[m\")\n",
    "\n",
    "            prev_loss = eval_loss\n",
    "\n",
    "print(f\"\\033[92mTraining complete; took: {time.time() - start_time:.2f} seconds; avg: {(time.time() - start_time) / EPOCHS:.2f} seconds/epoch; best: {prev_loss}\\033[0m\")"
   ],
   "id": "2c200d65a82d3b58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.plot(train_accuracies)\n",
    "plt.plot(eval_losses)\n",
    "plt.show()"
   ],
   "id": "94a616523955ce7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fragment_counts = sum([label == 1 for embedding, label in train_dataset])\n",
    "fragment_counts"
   ],
   "id": "36107866a7f8a26d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "non_fragment_counts = sum([label != 1 for embedding, label in train_dataset])\n",
    "non_fragment_counts"
   ],
   "id": "60d26d852b44369b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fragment_counts / non_fragment_counts",
   "id": "c1bf73c3426f99bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fragment_counts / (non_fragment_counts + fragment_counts)",
   "id": "34b11ca9432ef2e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "torch.save(model1.state_dict(), \"./model_saves2/final_model.pt\")"
   ],
   "id": "59ff9174828095e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open(\"../../experiments/true_fragment_embeddings/final_embeddings.pkl\", \"rb\") as p:\n",
    "    true_fragment_embeddings = pickle.load(p)\n",
    "\n",
    "true_fragment_dataset = RandomDataset(true_fragment_embeddings)"
   ],
   "id": "94ff42b50a5bb724"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "true_fragment_embeddings[0]",
   "id": "6d50cb1d6605653d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "true_fragment_loader = DataLoader(true_fragment_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)",
   "id": "9cbc12671b479b64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "model1.load_state_dict(torch.load(\"./model_saves2/random_model_epoch_10.pt\"))"
   ],
   "id": "1208e76cf8b19904"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_loss, test_accuracy = evaluate_binary(true_fragment_loader, model1, loss_fn, DEVICE)",
   "id": "509a99d907be9dda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_loss",
   "id": "5d2336b33a90d8a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_accuracy",
   "id": "ded83ad58449d1a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_val, display_labels=['Non-Fragment', 'Fragment'])\n",
    "disp.plot(cmap='Blues', ax=ax, values_format='d')\n",
    "ax.set_title('Confusion Matrix - Validation Set', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "1e584c07b28ce0d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Calculate metrics for both classes\n",
    "precision = precision_score(y_true_val, y_pred_val, average=None)\n",
    "recall = recall_score(y_true_val, y_pred_val, average=None)\n",
    "f1 = f1_score(y_true_val, y_pred_val, average=None)\n",
    "\n",
    "print(\"\\nMetrics by Class:\")\n",
    "print(f\"Class 0 (Non-Fragment) - Precision: {precision[0]:.4f}, Recall: {recall[0]:.4f}, F1: {f1[0]:.4f}\")\n",
    "print(f\"Class 1 (Fragment)     - Precision: {precision[1]:.4f}, Recall: {recall[1]:.4f}, F1: {f1[1]:.4f}\")\n",
    "\n",
    "# Calculate macro and weighted averages\n",
    "precision_macro = precision_score(y_true_val, y_pred_val, average='macro')\n",
    "recall_macro = recall_score(y_true_val, y_pred_val, average='macro')\n",
    "f1_macro = f1_score(y_true_val, y_pred_val, average='macro')\n",
    "\n",
    "precision_weighted = precision_score(y_true_val, y_pred_val, average='weighted')\n",
    "recall_weighted = recall_score(y_true_val, y_pred_val, average='weighted')\n",
    "f1_weighted = f1_score(y_true_val, y_pred_val, average='weighted')\n",
    "\n",
    "print(\"\\nMacro Average:\")\n",
    "print(f\"Precision: {precision_macro:.4f}, Recall: {recall_macro:.4f}, F1: {f1_macro:.4f}\")\n",
    "print(\"\\nWeighted Average:\")\n",
    "print(f\"Precision: {precision_weighted:.4f}, Recall: {recall_weighted:.4f}, F1: {f1_weighted:.4f}\")"
   ],
   "id": "3c4520ece4bbbbce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Calculate confusion matrix\n",
    "cm_val = confusion_matrix(y_true_val, y_pred_val)\n",
    "print(\"Confusion Matrix (Validation Set):\")\n",
    "print(cm_val)"
   ],
   "id": "7767565b4b3d7b02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get predictions on validation set\n",
    "y_true_val, y_pred_val = get_predictions(val_loader_eval, model1, DEVICE)"
   ],
   "id": "63160e3b75b4ccfa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a fresh validation loader without shuffling for consistent predictions\n",
    "val_loader_eval = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)"
   ],
   "id": "321ecad0cd924911"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Get predictions for validation dataset\n",
    "def get_predictions(dataloader, model, device: str):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device).float()\n",
    "            \n",
    "            logits = model(x)\n",
    "            preds = torch.sigmoid(logits)\n",
    "            predicted_labels = (preds >= 0.5).float()\n",
    "            \n",
    "            all_predictions.extend(predicted_labels.cpu().numpy().flatten())\n",
    "            all_labels.extend(y.cpu().numpy().flatten())\n",
    "    \n",
    "    return np.array(all_labels), np.array(all_predictions)"
   ],
   "id": "ee88c2406807627e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import sklearn metrics for confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "import numpy as np"
   ],
   "id": "9bc3055da8843886"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7c8864eff9c47138"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
