{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-24T19:47:32.313309Z",
     "start_time": "2025-11-24T19:47:31.205480Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch.cuda\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:47:32.330975Z",
     "start_time": "2025-11-24T19:47:32.316553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 1 # 1 because tokenizations sizes\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 1e-4"
   ],
   "id": "49277d8e8f88734a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:47:33.955946Z",
     "start_time": "2025-11-24T19:47:32.334063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(\"../../data/custom_fragments2/datasets/random_equal_distribution/random_equal_train.csv\")\n",
    "val_df = pd.read_csv(\"../../data/custom_fragments2/datasets/random_equal_distribution/random_equal_val.csv\")\n",
    "test_df = pd.read_csv(\"../../data/custom_fragments2/datasets/random_equal_distribution/random_equal_test.csv\")"
   ],
   "id": "b7073d70e573f7ce",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:47:33.998517Z",
     "start_time": "2025-11-24T19:47:33.996653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(train_df))\n",
    "print(len(val_df))\n",
    "print(len(test_df))"
   ],
   "id": "a47edb2023c0447",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478600\n",
      "119710\n",
      "149590\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:47:34.016277Z",
     "start_time": "2025-11-24T19:47:34.006585Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.head()",
   "id": "3ff5e02d84904284",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  source_accession fragment_type  \\\n",
       "0           A3Q8S8         mixed   \n",
       "1           Q6GLS4    terminal_N   \n",
       "2           P02607      complete   \n",
       "3           Q4WRR0      complete   \n",
       "4           A9INS6      complete   \n",
       "\n",
       "                                            sequence  is_fragment  \\\n",
       "0  MNGEKVKRLSTLAETLPIQVITPESFSLLFEGPKSRRQFIDWGAFH...         True   \n",
       "1  MPFGCVTLGDKKDYNHPTEVSDRYDLGQLIKTEEFCEVFRAKEKSS...         True   \n",
       "2  MCDFSEEQTAEFKEAFQLFDRTGDGKILYSQCGDVMRALGQNPTNA...        False   \n",
       "3  MGLTSILIAQVLFLGAANSAVVKRWPCSVSPTGPTDPSVAKNCGYW...        False   \n",
       "4  MELDIKAIMERLPHRYPMLLVDRVLDIVPGKSIVAIKNVSINEPFF...        False   \n",
       "\n",
       "   fragment_length  source_length  \n",
       "0              233            360  \n",
       "1              191            377  \n",
       "2              151            151  \n",
       "3              299            299  \n",
       "4              151            151  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_accession</th>\n",
       "      <th>fragment_type</th>\n",
       "      <th>sequence</th>\n",
       "      <th>is_fragment</th>\n",
       "      <th>fragment_length</th>\n",
       "      <th>source_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3Q8S8</td>\n",
       "      <td>mixed</td>\n",
       "      <td>MNGEKVKRLSTLAETLPIQVITPESFSLLFEGPKSRRQFIDWGAFH...</td>\n",
       "      <td>True</td>\n",
       "      <td>233</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q6GLS4</td>\n",
       "      <td>terminal_N</td>\n",
       "      <td>MPFGCVTLGDKKDYNHPTEVSDRYDLGQLIKTEEFCEVFRAKEKSS...</td>\n",
       "      <td>True</td>\n",
       "      <td>191</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P02607</td>\n",
       "      <td>complete</td>\n",
       "      <td>MCDFSEEQTAEFKEAFQLFDRTGDGKILYSQCGDVMRALGQNPTNA...</td>\n",
       "      <td>False</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4WRR0</td>\n",
       "      <td>complete</td>\n",
       "      <td>MGLTSILIAQVLFLGAANSAVVKRWPCSVSPTGPTDPSVAKNCGYW...</td>\n",
       "      <td>False</td>\n",
       "      <td>299</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A9INS6</td>\n",
       "      <td>complete</td>\n",
       "      <td>MELDIKAIMERLPHRYPMLLVDRVLDIVPGKSIVAIKNVSINEPFF...</td>\n",
       "      <td>False</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:47:35.358028Z",
     "start_time": "2025-11-24T19:47:34.035799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# t5 setup\n",
    "from transformers import T5Tokenizer, T5EncoderModel"
   ],
   "id": "b212103aaf10b83b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aenea\\Desktop\\Studium\\PP2\\protfrag\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:47:39.480669Z",
     "start_time": "2025-11-24T19:47:35.382631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", do_lower_case=False)\n",
    "t5model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\")"
   ],
   "id": "372c706e2090a914",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:47:39.493178Z",
     "start_time": "2025-11-24T19:47:39.491604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re"
   ],
   "id": "b23f03c280b3d806",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:47:39.497764Z",
     "start_time": "2025-11-24T19:47:39.495463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FragDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, tokenizer: T5Tokenizer):\n",
    "        self.input_ids = []\n",
    "        self.masks = []\n",
    "        self.labels = []\n",
    "        for row in dataframe.itertuples(index=False):\n",
    "            seq = \" \".join(list(re.sub(r\"[UZOB]\", \"X\", row.sequence)))\n",
    "            ids = tokenizer.encode_plus(seq, add_special_tokens=True)\n",
    "            self.input_ids.append(torch.tensor(ids[\"input_ids\"]))\n",
    "            self.masks.append(torch.tensor(ids[\"attention_mask\"]))\n",
    "            self.labels.append(torch.tensor(1.0 if row.is_fragment else 0.0, dtype=torch.float))\n",
    "\n",
    "        self.length = len(self.input_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.masks[idx], self.labels[idx]"
   ],
   "id": "e75442c4e34d54fd",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:49:40.904093Z",
     "start_time": "2025-11-24T19:47:39.499843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = FragDataset(train_df, tokenizer)\n",
    "train_dataset[0]"
   ],
   "id": "a2b749abc31dfde0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([19, 17,  5,  9, 14,  6, 14,  8,  4,  7, 11,  4,  3,  9, 11,  4, 13, 12,\n",
       "         16,  6, 12, 11, 13,  9,  7, 15,  7,  4,  4, 15,  9,  5, 13, 14,  7,  8,\n",
       "          8, 16, 15, 12, 10, 21,  5,  3, 15, 20, 11, 10, 14,  7, 15, 18, 11,  3,\n",
       "         21,  3, 17,  6,  8,  8, 12,  4, 14, 20,  8, 17, 16, 19,  4, 14,  7,  9,\n",
       "         11, 13, 18, 16, 16, 12, 16, 15, 21, 10, 14,  9,  4,  6,  8, 18,  3,  9,\n",
       "         12,  6, 11,  9, 12,  8, 14,  8, 18,  6,  5,  7,  4, 17,  9,  8,  4, 14,\n",
       "          5, 12, 12,  9,  9, 15,  4, 13, 16,  6, 10,  6, 14,  6,  7, 15, 11,  8,\n",
       "          5, 21, 10,  7,  4,  8,  6,  5, 11,  4, 13,  6, 16, 10,  3,  4,  7,  8,\n",
       "          5, 16,  4, 14,  4,  4,  6, 22,  3,  4,  8, 12,  3, 16,  5, 14,  4,  4,\n",
       "         14, 16, 16, 12, 10, 14, 17,  7, 12, 18,  4,  6, 10, 10,  4, 13,  7,  9,\n",
       "          4, 10,  3,  8, 20,  8, 16,  4,  4,  4, 16, 16,  4,  7, 10, 11,  5,  3,\n",
       "         16,  6, 15,  6, 11,  3, 12,  9, 13,  3,  3, 12, 19, 10,  7,  4, 17, 11,\n",
       "         13, 13,  6, 14,  6, 15, 20,  6,  9, 16,  5,  8,  6, 11,  6, 12,  9,  1]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:50:49.247028Z",
     "start_time": "2025-11-24T19:49:40.943900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_dataset = FragDataset(val_df, tokenizer)\n",
    "test_dataset = FragDataset(test_df, tokenizer)"
   ],
   "id": "21339602958843c9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:50:49.272813Z",
     "start_time": "2025-11-24T19:50:49.270095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ],
   "id": "943bc16b200f9245",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478600\n",
      "119710\n",
      "149590\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:50:49.290102Z",
     "start_time": "2025-11-24T19:50:49.288330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model\n",
    "import torch.nn as nn"
   ],
   "id": "c42b66742ba7f83e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:50:49.302565Z",
     "start_time": "2025-11-24T19:50:49.300162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, t5_model: T5EncoderModel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.t5 = t5_model\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, mask):\n",
    "        with torch.no_grad():\n",
    "            prot_emb = self.t5(input_ids=input_ids, attention_mask=mask).last_hidden_state[0].mean(dim=0)\n",
    "\n",
    "        return self.net(prot_emb)"
   ],
   "id": "3489d6abadca9ab2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:50:50.219463Z",
     "start_time": "2025-11-24T19:50:49.304785Z"
    }
   },
   "cell_type": "code",
   "source": "model = SimpleModel(t5model).to(DEVICE)",
   "id": "4abbed44ebe5aec",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:50:50.465680Z",
     "start_time": "2025-11-24T19:50:50.233099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    data1 = train_dataset[0]\n",
    "    print(model(data1[0].unsqueeze(0).to(DEVICE), data1[1].unsqueeze(0).to(DEVICE)))"
   ],
   "id": "41c691b8a233d71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0532], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:50:50.517852Z",
     "start_time": "2025-11-24T19:50:50.480491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    data1 = train_dataset[0]\n",
    "    print(model(data1[0].unsqueeze(0).to(DEVICE), data1[1].unsqueeze(0).to(DEVICE)).squeeze(-1))"
   ],
   "id": "74b625bf5d71eb2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0532, device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:51:14.115583Z",
     "start_time": "2025-11-24T19:51:14.112729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optim = torch.optim.Adam(model.net.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ],
   "id": "e580f5c204d036d7",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T19:59:34.357660Z",
     "start_time": "2025-11-24T19:56:03.625976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.train()\n",
    "train_loss = 0.0\n",
    "train_correct = 0\n",
    "train_count = 0\n",
    "\n",
    "for step, (input_ids, mask, label) in enumerate(train_loader, 1):\n",
    "    input_ids = input_ids.to(DEVICE)\n",
    "    mask = mask.to(DEVICE)\n",
    "    label = label.to(DEVICE)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    output = model(input_ids, mask)\n",
    "\n",
    "    loss = loss_fn(output, label)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    train_loss += loss.item()\n",
    "    pred = (torch.sigmoid(output) >= 0.5).float()\n",
    "    train_correct += (pred == label).sum().item()\n",
    "    train_count += 1\n",
    "\n",
    "    if train_count % 1000 == 0:\n",
    "        print(f\"Seq Count: {train_count}\")\n",
    "\n",
    "    if train_count % 10000 == 0:\n",
    "        print(f\"Train set {train_count}: Loss = {train_loss / 10000:.4f}, \"\n",
    "              f\"Accuracry = {train_correct / 10000:.4f}\")\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "\n",
    "        torch.save(model.state_dict(), f\"./simple_model_step_{train_count}.pt\")\n",
    "\n",
    "    if train_count % 100000 == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_count = 0\n",
    "        with torch.no_grad():\n",
    "            for v_input_ids, v_mask, v_label in val_loader:\n",
    "                v_input_ids = v_input_ids.to(DEVICE)\n",
    "                v_mask = v_mask.to(DEVICE)\n",
    "                v_label = v_label.to(DEVICE)\n",
    "\n",
    "                v_output = model(v_input_ids, mask)\n",
    "\n",
    "                v_loss = loss_fn(v_output, v_label)\n",
    "                val_loss += loss\n",
    "                v_pred = (torch.sigmoid(output) >= 0.5).float()\n",
    "                val_correct += (pred == label).sum().item()\n",
    "                val_count += 1\n",
    "\n",
    "        print(f\"Validation after {train_count} sequences: \"\n",
    "              f\"Loss = {val_loss / val_count:.4f}, \"\n",
    "              f\"Accuracy = {val_correct / val_count:.4f}\")\n",
    "        model.train()"
   ],
   "id": "1ac9083ffb0821ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq Count: 1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 18\u001B[39m\n\u001B[32m     15\u001B[39m loss.backward()\n\u001B[32m     16\u001B[39m optim.step()\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m train_loss += \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m pred = (torch.sigmoid(output) >= \u001B[32m0.5\u001B[39m).float()\n\u001B[32m     20\u001B[39m train_correct += (pred == label).sum().item()\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
